{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8b4e25f-3793-4366-8aae-4ea9d4427366",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import cv2\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ded3f2c-3cbb-4f79-b13f-a4b3f004fb36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class custom_dset(Dataset):\n",
    "    def __init__(self,\n",
    "                 img_path,\n",
    "                 txt_path,\n",
    "                 img_transform1,\n",
    "                 img_transform2,\n",
    "                 ):\n",
    "        with open(txt_path, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            self.img1_list = [\n",
    "                os.path.join(img_path, i.split()[0]) for i in lines\n",
    "            ]\n",
    "            self.img2_list = [\n",
    "                os.path.join(img_path, i.split()[1]) for i in lines\n",
    "            ]            \n",
    "            self.label_list = [i.split()[2] for i in lines]\n",
    "        self.img_transform1 = img_transform1\n",
    "        self.img_transform2 = img_transform2\n",
    "    def __getitem__(self, index):\n",
    "        img1_path = self.img1_list[index]\n",
    "        img2_path = self.img2_list[index]\n",
    "        label = self.label_list[index]\n",
    "        label=int(label)\n",
    "        img1 = cv2.imread(img1_path)\n",
    "        img2 = cv2.imread(img2_path)\n",
    "        img1 = img1.astype(np.float)/255\n",
    "        img2 = img2.astype(np.float)/255\n",
    "        img1 = cv2.resize(img1,(128,128), interpolation = cv2.INTER_AREA)\n",
    "        img2 = cv2.resize(img2,(128,128), interpolation = cv2.INTER_AREA)\n",
    "        img1 = self.img_transform1(img1)\n",
    "        img2 = self.img_transform2(img2)\n",
    "        return img1,img2,label\n",
    "    def __len__(self):\n",
    "        return len(self.label_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdaa2933-bce0-42dd-ac92-a42ae3f2c1a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Rescale(object):\n",
    "    def __call__(self, img):\n",
    "        if random.random()<0.7:\n",
    "            f = round(0.1*random.randint(7, 13),2)\n",
    "            if f>1:\n",
    "                img = cv2.resize(img,None,fx=f, fy=f, interpolation = cv2.INTER_CUBIC)\n",
    "                a = int(round((f*128-128)/2))\n",
    "                img = img[a:a+128,a:a+128]\n",
    "            else:\n",
    "                img = cv2.resize(img,None,fx=f, fy=f, interpolation = cv2.INTER_AREA)\n",
    "                a= int(round((128-f*128)/2))\n",
    "                temp=np.zeros([128,128,3],dtype=np.uint8)\n",
    "                temp.fill(0) \n",
    "                for i in range(img.shape[0]):\n",
    "                    for j in range(img.shape[1]):\n",
    "                        temp[i+a,j+a]=img[i,j]\n",
    "                img=temp\n",
    "        return img\n",
    "\n",
    "class Flip(object):\n",
    "    def __call__(self,img):\n",
    "        if random.random()<0.7:\n",
    "            return cv2.flip(img,1)\n",
    "        return img\n",
    "        \n",
    "class Rotate(object):\n",
    "    def __call__(self,img):\n",
    "        if random.random()<0.7:\n",
    "            angle=random.random()*60-30\n",
    "            rows,cols,cn = img.shape\n",
    "            M = cv2.getRotationMatrix2D((cols/2,rows/2),angle,1)\n",
    "            img = cv2.warpAffine(img,M,(cols,rows))\n",
    "            return img\n",
    "        return img\n",
    "\n",
    "class Translate(object):\n",
    "    def __call__(self,img):\n",
    "        if random.random()<0.7:\n",
    "            x=random.random()*20-10\n",
    "            y=random.random()*20-10\n",
    "            rows,cols,cn = img.shape\n",
    "            M= np.float32([[1,0,x],[0,1,y]])\n",
    "            img = cv2.warpAffine(img,M,(cols,rows))\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a253d91a-54de-492d-ad6a-fba212be2102",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "img_path = ''\n",
    "txt_path = ''\n",
    "\n",
    "lr = 1e-6\n",
    "num_epoches = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff1e898e-def9-43ef-9d67-9b392984e77c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m transform1 \u001b[38;5;241m=\u001b[39m transforms\u001b[38;5;241m.\u001b[39mCompose([Rescale(),Flip(),Translate(),Rotate(),transforms\u001b[38;5;241m.\u001b[39mToTensor(),\n\u001b[1;32m      2\u001b[0m                     transforms\u001b[38;5;241m.\u001b[39mNormalize((\u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0.5\u001b[39m), (\u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0.5\u001b[39m))]) \n\u001b[1;32m      3\u001b[0m transform2 \u001b[38;5;241m=\u001b[39m transforms\u001b[38;5;241m.\u001b[39mCompose([Rescale(),Flip(),Translate(),Rotate(),transforms\u001b[38;5;241m.\u001b[39mToTensor(),\n\u001b[1;32m      4\u001b[0m                     transforms\u001b[38;5;241m.\u001b[39mNormalize((\u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0.5\u001b[39m), (\u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0.5\u001b[39m))])                \n\u001b[0;32m----> 5\u001b[0m train_set \u001b[38;5;241m=\u001b[39m \u001b[43mcustom_dset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtxt_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtransform1\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtransform2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m DataLoader(train_set, batch_size\u001b[38;5;241m=\u001b[39mN, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "Cell \u001b[0;32mIn[2], line 8\u001b[0m, in \u001b[0;36mcustom_dset.__init__\u001b[0;34m(self, img_path, txt_path, img_transform1, img_transform2)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m      3\u001b[0m              img_path,\n\u001b[1;32m      4\u001b[0m              txt_path,\n\u001b[1;32m      5\u001b[0m              img_transform1,\n\u001b[1;32m      6\u001b[0m              img_transform2,\n\u001b[1;32m      7\u001b[0m              ):\n\u001b[0;32m----> 8\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtxt_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      9\u001b[0m         lines \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mreadlines()\n\u001b[1;32m     10\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimg1_list \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     11\u001b[0m             os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(img_path, i\u001b[38;5;241m.\u001b[39msplit()[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m lines\n\u001b[1;32m     12\u001b[0m         ]\n",
      "File \u001b[0;32m/home/conda/eurodatacube9/90e95dc9cfbb71bf348325654881a0f5bf1b4b66f9001f8cf531c2af1b0c08c5-20230928-051020-453458-296-edc-g/lib/python3.10/site-packages/IPython/core/interactiveshell.py:286\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    283\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    284\u001b[0m     )\n\u001b[0;32m--> 286\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: ''"
     ]
    }
   ],
   "source": [
    "transform1 = transforms.Compose([Rescale(),Flip(),Translate(),Rotate(),transforms.ToTensor(),\n",
    "                    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]) \n",
    "transform2 = transforms.Compose([Rescale(),Flip(),Translate(),Rotate(),transforms.ToTensor(),\n",
    "                    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])                \n",
    "train_set = custom_dset(img_path, txt_path,transform1,transform2)\n",
    "train_loader = DataLoader(train_set, batch_size=N, shuffle=True, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69c80ce5-0a05-4898-8ad1-447e4fb2b1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cnn(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Cnn, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 5, 1, 2),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, 5, 1, 2),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            )\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            )\n",
    "        self.conv4 =nn.Sequential(\n",
    "            nn.Conv2d(256, 512, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(512),\n",
    "            )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(131072, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(1024),\n",
    "        )\n",
    "  \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "059f85f5-072d-4037-b1be-ce1c41f9db41",
   "metadata": {},
   "outputs": [],
   "source": [
    "net=Cnn()         \n",
    "if torch.cuda.is_available() :\n",
    "    net = net.cuda()  \n",
    "    \n",
    "optimizer = torch.optim.Adam(net.parameters(), lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4133e955-f3f7-4f8a-a478-460f9eef0701",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContrastiveLoss(nn.Module):\n",
    "    def __init__(self, margin=1.0):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, output1, output2, label):\n",
    "        euclidean_distance = F.pairwise_distance(output1, output2)\n",
    "        loss_contrastive = torch.mean((label) * torch.pow(euclidean_distance, 2) + (1-label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))\n",
    "\n",
    "        return loss_contrastive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f72900a-d6f0-4e43-83bc-fdb7cc57efaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = ContrastiveLoss() \n",
    "l_his=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0a4916-0998-4a6d-a173-6da5619dd226",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_only = 0\n",
    "\n",
    "if test_only==0:\n",
    "    for epoch in range(num_epoches):\n",
    "        print('Epoch:', epoch + 1, 'Training...')\n",
    "        running_loss = 0.0 \n",
    "        for i,data in enumerate(train_loader, 0):\n",
    "            image1s,image2s,labels=data\n",
    "            if torch.cuda.is_available():\n",
    "                image1s = image1s.cuda()\n",
    "                image2s = image2s.cuda()\n",
    "                labels = labels.cuda()\n",
    "            image1s, image2s, labels = Variable(image1s), Variable(image2s), Variable(labels.float())\n",
    "            optimizer.zero_grad()\n",
    "            f1=net(image1s)\n",
    "            f2=net(image2s)\n",
    "            loss = loss_func(f1,f2,labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if i % 5 == 4:\n",
    "                l_his.append(loss.data[0])\n",
    "            # print statistics\n",
    "            running_loss += loss.data[0]\n",
    "            if i % 100 == 99:    \n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                      (epoch + 1, i + 1, running_loss / 100))\n",
    "                running_loss = 0.0\n",
    "    print('Finished Training')\n",
    "    fig = plt.figure()\n",
    "    ax = plt.subplot(111)\n",
    "    ax.plot(l_his)    \n",
    "    plt.xlabel('Steps')  \n",
    "    plt.ylabel('Loss')  \n",
    "    fig.savefig('plott2.png')  \n",
    "    torch.save(net.state_dict(), name)\n",
    "else:   \n",
    "    net.load_state_dict(torch.load(name))\n",
    "    transform = transforms.Compose([transforms.ToTensor(),\n",
    "                        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]) \n",
    "    test_set = custom_dset('./lfw', './train.txt',transform,transform)\n",
    "    test_loader = DataLoader(test_set, batch_size=N, shuffle=True, num_workers=2)   \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for data in test_loader:\n",
    "        image1s,image2s,labels = data\n",
    "        if torch.cuda.is_available():\n",
    "            image1s = image1s.cuda()\n",
    "            image2s = image2s.cuda()\n",
    "            labels = labels.cuda()\n",
    "        image1s, image2s, labels = Variable(image1s), Variable(image2s), Variable(labels.float())   \n",
    "        f1=net(image1s)\n",
    "        f2=net(image2s)\n",
    "        dist = F.pairwise_distance(f1, f2)\n",
    "        dist = dist.cpu()\n",
    "        for j in range(dist.size()[0]):\n",
    "            if ((dist.data.numpy()[j]<0.8)):\n",
    "                if labels.cpu().data.numpy()[j]==1:\n",
    "                    correct +=1\n",
    "                    total+=1\n",
    "                else:\n",
    "                    total+=1\n",
    "            else:\n",
    "                if labels.cpu().data.numpy()[j]==0:\n",
    "                    correct+=1\n",
    "                    total+=1\n",
    "                else:\n",
    "                    total+=1                \n",
    "    print('Accuracy of the network on the train images: %d %%' % (\n",
    "        100 * correct / total))\n",
    "    \n",
    "    test_set = custom_dset('./lfw', './test.txt',transform,transform)\n",
    "    test_loader = DataLoader(test_set, batch_size=N, shuffle=True, num_workers=2)  \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for data in test_loader:\n",
    "        image1s,image2s,labels = data\n",
    "        if torch.cuda.is_available():\n",
    "            image1s = image1s.cuda()\n",
    "            image2s = image2s.cuda()\n",
    "            labels = labels.cuda()\n",
    "        image1s, image2s, labels = Variable(image1s), Variable(image2s), Variable(labels.float())   \n",
    "        f1=net(image1s)\n",
    "        f2=net(image2s)\n",
    "        dist = F.pairwise_distance(f1, f2)\n",
    "        dist = dist.cpu()\n",
    "        for j in range(dist.size()[0]):\n",
    "            if ((dist.data.numpy()[j]<0.8)):\n",
    "                if labels.cpu().data.numpy()[j]==1:\n",
    "                    correct +=1\n",
    "                    total+=1\n",
    "                else:\n",
    "                    total+=1\n",
    "            else:\n",
    "                if labels.cpu().data.numpy()[j]==0:\n",
    "                    correct+=1\n",
    "                    total+=1\n",
    "                else:\n",
    "                    total+=1                \n",
    "    print('Accuracy of the network on the test images: %d %%' % (\n",
    "        100 * correct / total))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eurodatacube9-edc-g",
   "language": "python",
   "name": "conda-env-eurodatacube9-edc-g-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
